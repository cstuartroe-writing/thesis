\chapter{Research proposal}

The primary research question of this thesis is which typological, lexical, and genealogical similarities, if any, are predictive of more effective transfer learning of morphology between languages. For instance, if language A is exclusively prefixing while languages B and C are exclusively suffixing, and if there is considerably less training data available for language C than the others, is it likely that a neural model pre-trained on language B is likely to make a better transfer learning candidate for modeling language C than one pre-trained on language A, due to the relative typological similarity between B and C?

Fortunately, I already have access to a morphological dataset for 103 languages, which can be used to train neural morphology models. In order to measure typological similarities, I'll need to compile a set of typological category information for these 103 languages, using existing research and computational analysis of the morphological dataset. Typological characteristics I'm planning on assessing include affixation strategy, set of grammatical categories inflected for, overall morphological paradigm size, occurrence of fusion between grammatical categories, and presence of long-distance morphophonological processes and/or reduplication. I will also assess genealogical closeness and potentially lexical similarity. The details of my data sourcing and generation can be found in section 4.

To assess transfer learning efficacy, I will first training and scoring models for all 103 languages with low (~100 forms) and/or medium (~1,000 forms) resource settings as a baseline. I can then pre-train models on some or all of the 103 languages with a high-resource (~10,000 forms) setting, and use these as the basis of transfer learned models of other languages with low and medium-resource training sets and assess their performance relative to models without access to transfer learning. With a diverse enough data set of language pairs it should be possible to assess the effect of typological, lexical, and genealogical similarities on transfer learning via simple regression. Tentatively, I will choose a few hundred pairs randomly with weighting towards pairs of similar languages, since the majority of randomly chosen pairs will be typologically and genealogically distant.

For the architecture of the neural models, I will use some variant of LSTM; I will base it on one or more of the best-performing models submitted to SIGMORPHON 2019.