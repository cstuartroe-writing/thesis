% !TEX root = ../thesis-example.tex
%
\pdfbookmark[0]{Abstract}{Abstract}
\chapter*{Abstract}
\label{sec:abstract}
\vspace*{-10mm}

In the SIGMORPHON 2019 shared task 1, multiple teams attempted for the first time to leverage transfer learning to build more accurate models of natural language morphology with small amounts of target domain data, with the intended goal of boosting modeling resources for low-resource languages. The performance of those models can be compared to the previous year's non-transfer learning task on the same data with the same goal, to find patterns in the efficacy of transfer learning to this computational problem. There is a highly robust relationship between similar verbal morphology and effective transfer learning outcomes between distantly related and unrelated source and target languages. Other relationships between the genealogical distance and data set similarities between source and target language also appear, but are less robust and have a less clear explanation. In order to ascertain the nature of these correlations suggested by existing data, a larger sampling of unrelated language pairs and a principled approach to isolating the effect of transfer learning should be undertaken. It may also be fruitful to measure lexical similarity and other types of typological similarities, such as the occurrence of morphological fusion and long-distance morphophonological processes, to investigate what effects they may have on transfer learning efficacy.